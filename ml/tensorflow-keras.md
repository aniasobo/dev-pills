# Tensorflow 2.0 with Keras

[Notes from A Practical Guide to Deep Learning with TensorFlow 2.0 and Keras](https://github.com/Vadikus/practicalDL)

### Jupyter

- runs with `$ jupyter notebook .` in your proj directory
- local server, runs the notebook on port `8888` by default
- runs a python interpreter
- notebooks are in markdown and can be browser-edited
- tensorflow functions can be executed in them too
- run shell commands in Jupyter by prepending them with a bang, like `!pip install bla`

### Books

- [ ] _Deep Learning With Python_ Francois Chollet (owner/maintainter of Keras) - [link to Jupyter code examples](https://github.com/fchollet/deep-learning-with-python-notebooks) - [link to Amazon](https://www.amazon.co.uk/gp/product/1617294438/)
- [ ] _Hands-on ML with Scikit-Learn, Keras & TensorFlow_ by Geron - [link to Jupyter examples](https://github.com/ageron/handson-ml2) - [link to Amazon](https://www.amazon.co.uk/gp/product/1492032646/)
- [ ] _Hands On Neural Networks with TensorFlow 2.0_ by Galeone - [link to repo](https://github.com/PacktPublishing/Hands-On-Neural-Networks-with-TensorFlow-2.0) - [link to Amazon](https://www.amazon.co.uk/gp/product/1789615550/)

### Neuron layers

- the concept of `weight` of data channels/signals that reach the neuron
- input signals \* sum of their weights + constant
- active/inactive neuron outputs `1` / `0`
- sigmoid function - ??
- same inputs processed by neurons within a neural layer (or multiple) allow us to run statistical calcs on the output
- the depth of neural layers that feed into the output is where the concept of Deep Learning came from
- performance in ML == accuracy
- convolutional neural network - not all neurons in a layer are connected to the next layer's neurons (as opposed to one where they are all connected)

### Training models

- weights and biases are random in the first step of model training
- forward propagation - processing in the neural layers outputting towards the decision
- backward propagation - reinforce the correct connection between neurons by increasing the weights by feeding back when the decision was correct; penalise the incorrect predictions by weakening the weights
- things to provide your compute with: data and algorithm/model; then the output data is fed back to the compute (backward propagation)
- data - annotated data set - the decision must be verifiable
- principle: reducing the information
- possible output - see Jupyter notebook for Creating a stylist for images

---

## Linear regression

### Jupyter notebook setup

- manual setup vs helper functions of ts
- <kbd>TAB</kbd> in Jupyter is autocomplete, showing you available funcs
- execute: <kbd>SHIFT</kbd> + <kbd>â†µ</kbd> - executes current snippet and opens another with cursor
- to debug - add `?` in your code/command you're about to execute, then execute

```
import tensorflow as tf // execute this line

// assign a Tensor object to a variable

var = tf.random.uniform([1])

// represent that Tensor as a numpy

print(var.numpy()) // execute
```

- `%matplotlib inline` prints all the images generated by `matplotlib` inline
- install the module `matplotlib` with `pip` first

### Hardware & compiler

- hardware: CPUs, GPUs, whatever does the number crunching; works in binary
- the binary code is created by the compilers
- we pass the source code (C/C++) to the compiler
- python is an interpreted language; C and C++ are compiled languages
- C/C++ -> compiler -> binary object file -> executable -> hardware
- python -> interpreter -> low level language
- TensorFlow tries to optimise hardware utilisation
- it's written in C and C++, using python to describe the model and yield it in C++
- Keras - higher-level API using TensorFlow
- computational graph - all the python code, optimised to be rebuilt in nodes on the lower level
- memory allocation is a time-consuming operation; TS can assign a comp graph to a buffer

### TensorFlow architecture

- NumPy - numeric python - TS uses its mathematical operations; the link between python and C
- computational graph creation is now eager execution (in TS 2.0) - help with debugging
- PyTorch had eager execution from the beginning, so it was faster than TensorFlow 1.0
- you couldn't see the values until the computational graph was created in 1.0

### Plotting uniform data

- linear regression - the grandfather of your neural networks
- normal distribution - bell curve

### Predicting data, visualising learning rate & loss

- loss function and calculating error:

```
def mean_squared_error(y_pred, Y):
      return tf.reduce_mean(tf.square(y_pred-Y))
```

- **minimise the loss function to get more accurate data**
- choose the set that gives you the smallest loss function values (the most accurate set)
- do that by differentiation (this is what happens during back propagation)
- learning rate function takes a min number of steps to take, a for loop
- GradientTape for calculating derivatives:

```
w = tf.Variable(0.0)
b = tf.Variable(-1.0)

learning_rate = 0.1
steps = 200

for step in range(steps):
    with tf.GradientTape() as tape:
        # this block of code will conduct math operations with this GT
        predictions = predict(X, w=w, b=b)
        loss = mean_squared_error(predictions, Y)

    gradient = tape.gradient(loss, [w, b]) # array

    w.assign_sub(gradient[0]*learning_rate)
    b.assign_sub(gradient[1]*learning_rate)

    if step%20==0:
        print("Step {}".format(step))
```

- loss funct = measurement of the error
- loss funct should return a large value in the first steps of model training
- loss function is hyperbolic
- its value should keep reducing the longer the model trains
- number of steps and the learning rate influence how long the model will run for
- learning rate depends on the problem; independent of the number of steps, but you need both to get to the optimal solution

---

## Image processing & model training

Adding Keras to project:

```
import tensorflow as tf
from tensorflow import keras
```

- Keras has example datasets, like: `keras.datasets.boston_housing` , `keras.datasets.cifar` contains images, `keras.datasets.mnist` (also a fashion version)
- stages: 1. training the model with input data from x and y, then 2. x test and y test to test the model
- models use floating point numbers, not integers, to train `x_train = x_train/255.0 # cast ints into floating points`
- use Keras APIs and sequentials to define your model:

```
from tensorflow.keras import Sequential # the class that describes the models
# layers of the model will be added sequentially
from tensorflow.keras.layers import Dense, Flatten
# flatten the image out into a one dimensional array, connect all layers with Dense

# specify the model type
model = Sequential()

# add input shape in px
model.add(Flatten(input_shape=(28,28)))
model.add(Dense(units=256,activation='relu')) # add 256 neurons to the layer, each neuron will see the whole picture
# rectified limited unit
model.add(Dense(units=10, activation='softmax')) # connect the 256 from the first layer to the 10 on this layer
# softmax normalizes the output of the 10 units to 1

model.summary() # what is going on in the model
# no data, weigths or biases yet
```

- reLU is so fast because it only returns 0 or x depending on which one it's closer to; sigmoid takes more time because it finds the proper value and its exponents (CPU requires more iterations while reLU takes 1)
- each neuron we add to the first layer will see each pixel, i.e. the whole picture
- the Dense layer connects all the neurons to all the pixels
- the second Dense layer connects all neurons from the previous layer to all of its neurons
- 10\*256 weights + 10 biases - the numbers used to preserve the state

### solver & loss function

- solver - must contain the manner of getting to the solution and the loss function
- keras and TS function can be mixed and matched, like in the loss func

```
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# the solver func
# adam is a solver type
# metrics takes an array of traits to measure by
```

### Training a model

- `epoch` - event of showing the model the totality of the input data
- to start the model training: `model.fit(x_train, y_train, epochs=20)`
- running again with test data `model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))`
- check the history of the model training:

```
h=model.history.history # execute

plt.plot(h['accuracy'])
plt.plot(h['val_accuracy'])
# generates a graph
```

- add multiple layers of neurons with trainign data to make a better model - layers can have less and less neurons

```
model = Sequential()

model.add(Flatten(input_shape=(28,28)))
model.add(Dense(units=20, activation='relu'))
model.add(Dense(units=20, activation='relu'))
model.add(Dense(units=16, activation='relu'))
model.add(Dense(units=10, activation='softmax'))
```

---

## Convolution & pooling
